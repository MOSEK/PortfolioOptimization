{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaTeX macros (hidden cell)\n",
    "$\n",
    "\\newcommand{\\Q}{\\mathcal{Q}}\n",
    "\\newcommand{\\ECov}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\EMean}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\EAlpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\EBeta}{\\boldsymbol{\\beta}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "FILE=/content/portfolio_tools.py\n",
    "if [[ ! -f $FILE ]]; then\n",
    "    wget https://raw.githubusercontent.com/MOSEK/PortfolioOptimization/main/python/notebooks/portfolio_tools.py\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mosek \n",
    "%env PYTHONPATH /env/python:/content\n",
    "%env MOSEKLM_LICENSE_FILE /content/mosek.lic:/root/mosek/mosek.lic\n",
    "\n",
    "# To execute the notebook directly in colab make sure your MOSEK license file is in one the locations\n",
    "#\n",
    "# /content/mosek.lic   or   /root/mosek/mosek.lic\n",
    "#\n",
    "# inside this notebook's internal filesystem. \n",
    "#\n",
    "# You will also need an API key from a stock data provider, or ready data files in a \"stock_data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import brentq\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from mosek.fusion import *\n",
    "import mosek.fusion.pythonic          # From MOSEK >= 10.2\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "\n",
    "# portfolio_tools.py is a Mosek helper file distributed together with the notebooks\n",
    "from portfolio_tools import data_download, DataReader, compute_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version checks\n",
    "print(sys.version)\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "\n",
    "# Jupyter configuration\n",
    "c = ConfigManager()\n",
    "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})  \n",
    "\n",
    "# Numpy options\n",
    "np.set_printoptions(precision=5, linewidth=120, suppress=True)\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Matplotlib options\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the raw data that will be used to compute the optimization input variables, the vector $\\EMean$ of expected returns and the covariance matrix $\\ECov$. The data consists of daily stock prices of $8$ stocks from the US market. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data downloading:\n",
    "# If the user has an API key for alphavantage.co, then this code part will download the data. \n",
    "# The code can be modified to download from other sources. To be able to run the examples, \n",
    "# and reproduce results in the cookbook, the files have to have the following format and content:\n",
    "# - File name pattern: \"daily_adjusted_[TICKER].csv\", where TICKER is the symbol of a stock. \n",
    "# - The file contains at least columns \"timestamp\", \"adjusted_close\", and \"volume\".\n",
    "# - The data is daily price/volume, covering at least the period from 2016-03-18 until 2021-03-18, \n",
    "# - Files are for the stocks PM, LMT, MCD, MMM, AAPL, MSFT, TXN, CSCO.\n",
    "list_stocks = [\"PM\", \"LMT\", \"MCD\", \"MMM\", \"AAPL\", \"MSFT\", \"TXN\", \"CSCO\"]\n",
    "list_factors = [\"SPY\", \"IWM\"]\n",
    "alphaToken = None\n",
    " \n",
    "list_tickers = list_stocks + list_factors\n",
    "if alphaToken is not None:\n",
    "    data_download(list_tickers, alphaToken)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the daily stock price data from the downloaded CSV files. The data is adjusted for splits and dividends. Then a selected time period is taken from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_start = \"2016-03-18\"\n",
    "investment_end = \"2021-03-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The files are in \"stock_data\" folder, named as \"daily_adjusted_[TICKER].csv\"\n",
    "dr = DataReader(folder_path=\"stock_data\", symbol_list=list_tickers)\n",
    "dr.read_data()\n",
    "df_prices, _ = dr.get_period(start_date=investment_start, end_date=investment_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the optimization model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we implement the optimization model in Fusion API. We create it inside a function so we can call it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |x| <= t\n",
    "def absval(M, x, t):\n",
    "    M.constraint(t + x >= 0)\n",
    "    M.constraint(t - x >= 0)\n",
    "    \n",
    "    \n",
    "def sqrtm_symm(m):\n",
    "    e, v = np.linalg.eigh(m)\n",
    "    sqrt_e = np.sqrt(e)\n",
    "    sqrt_m = np.dot(v, np.dot(np.diag(sqrt_e), v.T))\n",
    "    return sqrt_m\n",
    "\n",
    "    \n",
    "def EfficientFrontier(N, mu0, gamma, beta0, Gmx, rho, diag_S_theta_upper, Q0, Nmx, zeta, deltas):\n",
    "\n",
    "    with Model(\"Case study\") as M:\n",
    "        # Settings\n",
    "        #M.setLogHandler(sys.stdout)\n",
    "        \n",
    "        # Get number of factors\n",
    "        K = Q0.shape[0]\n",
    "        \n",
    "        # Variables \n",
    "        # The variable x is the fraction of holdings in each security. \n",
    "        # It is restricted to be positive, which imposes the constraint of no short-selling.   \n",
    "        x = M.variable(\"x\", N, Domain.greaterThan(0.0))\n",
    "        z = M.variable(\"z\", N, Domain.greaterThan(0.0))\n",
    "        \n",
    "        # Constrain absolute value\n",
    "        absval(M, x, z)\n",
    "        \n",
    "        # The variable t1 and t2 models the factor and specific portfolio variance terms.\n",
    "        t1 = M.variable(\"t1\", 1, Domain.greaterThan(0.0))\n",
    "        t2 = M.variable(\"t2\", 1, Domain.greaterThan(0.0))\n",
    "        \n",
    "        # The variables tau, s, u help modeling the factor risk.\n",
    "        tau = M.variable(\"tau\", 1, Domain.greaterThan(0.0))\n",
    "        s = M.variable(\"s\", 1, Domain.greaterThan(0.0))\n",
    "        u = M.variable(\"u\", K, Domain.greaterThan(0.0))\n",
    "    \n",
    "        # Budget constraint\n",
    "        M.constraint('budget', Expr.sum(x), Domain.equalsTo(1.0))\n",
    "        \n",
    "        # Objective (variance minimization)\n",
    "        delta = M.parameter()\n",
    "        wc_return = x.T @ mu0 - z.T @ gamma\n",
    "        M.objective('obj', ObjectiveSense.Maximize, wc_return - delta * (t1 + t2))\n",
    "                       \n",
    "        # Risk constraint (specific)\n",
    "        M.constraint('spec-risk', Expr.vstack(t2, 0.5, Expr.mulElm(np.sqrt(diag_S_theta_upper), x)), Domain.inRotatedQCone())\n",
    "                    \n",
    "        # Risk constraint (factor)\n",
    "        siG = sqrtm_symm(np.linalg.inv(Gmx))            \n",
    "        H = siG @ (Q0 + zeta * Nmx) @ siG \n",
    "        lam, V = np.linalg.eigh(H)\n",
    "        w = (V.T @ sqrtm_symm(H) @ sqrtm_symm(Gmx) @ beta0.T) @ x\n",
    "        M.constraint('fact-risk-1', t1 >= tau + Expr.sum(u))\n",
    "        M.constraint('fact-risk-2', s <= 1.0 / lam[-1])\n",
    "        M.constraint('fact-risk-3', Expr.vstack(s, 0.5 * tau, z.T @ rho), Domain.inRotatedQCone())\n",
    "        col1 = Expr.constTerm(K, 1.0) - Expr.mulElm(Expr.repeat(s, K, 0), lam)\n",
    "        M.constraint('fact-risk-4', Expr.hstack(col1, 0.5 * u, w), Domain.inRotatedQCone())\n",
    "    \n",
    "        # Create DataFrame to store the results. Last security names (the factors) are removed.\n",
    "        columns = [\"delta\", \"obj\", \"return\", \"risk\", \"zdiff\"] + df_prices.columns[:-K].tolist()\n",
    "        df_result = pd.DataFrame(columns=columns)\n",
    "        for d in deltas:\n",
    "            # Update parameter\n",
    "            delta.setValue(d)\n",
    "            \n",
    "            # Solve optimization\n",
    "            M.solve()\n",
    "            \n",
    "            # Check if the solution is an optimal point\n",
    "            solsta = M.getPrimalSolutionStatus()\n",
    "            if (solsta != SolutionStatus.Optimal):\n",
    "                # See https://docs.mosek.com/latest/pythonfusion/accessing-solution.html about handling solution statuses.\n",
    "                raise Exception(\"Unexpected solution status!\")\n",
    "            \n",
    "            # Save results\n",
    "            portfolio_return = mu0 @ x.level() - gamma @ z.level()\n",
    "            portfolio_risk = np.sqrt((t1.level() + t2.level())[0])\n",
    "            zdiff = np.sum(np.abs(x.level()) - z.level())\n",
    "            row = pd.Series([d, M.primalObjValue(), portfolio_return, portfolio_risk, zdiff] + list(x.level()), index=columns)\n",
    "            df_result = pd.concat([df_result, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the factor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to make scenarios. The input is the expected return and covariance of yearly logarithmic returns. The reason for this is that it is easier to generate logarithmic return scenarios from normal distribution than generating linear return scenarios from lognormal distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenarios(m_log, S_log, factor_num):\n",
    "    \"\"\"\n",
    "    It is assumed that the last factor_num coordinates correspond to the factors.\n",
    "    \"\"\"\n",
    "    if factor_num < 1: \n",
    "        raise Exception(\"Does not make sense to compute a factor model without factors!\")\n",
    "    \n",
    "    # Generate logarithmic return scenarios\n",
    "    scenarios_log = np.random.default_rng().multivariate_normal(m_log, S_log, 100000)\n",
    "    \n",
    "    # Convert logarithmic return scenarios to linear return scenarios \n",
    "    scenarios = np.exp(scenarios_log) - 1\n",
    "    \n",
    "    R = scenarios[:, :-factor_num]\n",
    "    F = scenarios[:, -factor_num:]\n",
    "    \n",
    "    return R, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function that computes the factor model\n",
    "$$\n",
    "R_t = \\mu + \\beta F_{t} + \\theta_t.\n",
    "$$\n",
    "\n",
    "The function can handle any number of factors, and returns estimates $\\EMean$, $\\EBeta$, $\\ECov_F$, $\\ECov_\\theta$, and the factor return matrix. The factors are assumed to be at the last coordinates of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_model(R, F):\n",
    "    \"\"\"\n",
    "    It is assumed that the last factor_num coordinates correspond to the factors.\n",
    "    \"\"\"\n",
    "    factor_num = F.shape[1]\n",
    "    \n",
    "    # Do linear regression \n",
    "    params = []\n",
    "    resid = []\n",
    "    X = F\n",
    "    X = sm.add_constant(X, prepend=True)\n",
    "    \n",
    "    for k in range(N):\n",
    "        y = R[:, k]\n",
    "        model = sm.OLS(y, X, hasconst=True).fit()        \n",
    "        resid.append(model.resid)        \n",
    "        params.append(model.params)\n",
    "    resid = np.array(resid)\n",
    "    params = np.array(params)\n",
    "    \n",
    "\n",
    "    # Get parameter estimates\n",
    "    mu = params[:, 0]\n",
    "    B = params[:, 1:]\n",
    "    \n",
    "    S_F = np.atleast_2d(np.cov(X[:, 1:].T))  # MLE computed from data\n",
    "    S_theta = np.cov(resid, ddof=factor_num + 1)   \n",
    "    diag_S_theta = np.diag(S_theta)\n",
    "    \n",
    "    return mu, B, S_F, diag_S_theta, X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define functions that will compute the parametrization for the uncertainty sets of the factor model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unc_mu(mu_est, diag_S_theta_est, A, omega):\n",
    "    K = A.shape[1] - 1\n",
    "    T = A.shape[0]\n",
    "    iAA = np.linalg.inv(A.T @ A)\n",
    "    c = stats.f.ppf(omega, K + 1, T - K - 1)\n",
    "\n",
    "    # Parametrization\n",
    "    mu0 = mu_est\n",
    "    gamma = np.sqrt(diag_S_theta_est) * np.sqrt((K + 1) * iAA[0, 0] * c)\n",
    "    \n",
    "    return mu0, gamma\n",
    "\n",
    "def unc_beta(beta_est, diag_S_theta_est, A, omega):\n",
    "    K = A.shape[1] - 1\n",
    "    T = A.shape[0]\n",
    "    F = A[:,1:].T\n",
    "    F1 = F @ np.ones((T, 1))\n",
    "    c = stats.f.ppf(omega, K + 1, T - K - 1)\n",
    "\n",
    "    # Parametrization\n",
    "    beta0 = beta_est\n",
    "    Q = np.array([[0, 1, 0], [0, 0, 1]])\n",
    "    iAA = np.linalg.inv(A.T @ A)\n",
    "    Gmx = F @ F.T - F1 @ F1.T / T\n",
    "    rho = np.sqrt(diag_S_theta_est) * np.sqrt((K + 1) * c)\n",
    "    \n",
    "    return beta0, Gmx, rho\n",
    "\n",
    "def unc_d(diag_S_theta_est, percent):    \n",
    "    # Here we just add a percentage to the estimated error variance, to get an upper bound estimate. \n",
    "    diag_S_theta_upper = diag_S_theta_est * (1.0 + percent)\n",
    "    return diag_S_theta_upper\n",
    "\n",
    "def unc_q(S_F, A, omega):\n",
    "    T = A.shape[0]\n",
    "      \n",
    "    \n",
    "    def fun(eta, T, omega):\n",
    "        return stats.gamma.cdf(1 + eta, (T + 1) / 2, scale=2 / (T - 1)) - \\\n",
    "               stats.gamma.cdf(1 - eta, (T + 1) / 2, scale=2 / (T - 1)) - \\\n",
    "               omega\n",
    "    \n",
    "\n",
    "    eta = brentq(fun, 0, 1, args=(T, omega))\n",
    "    \n",
    "    # Parametrization\n",
    "    Q0 = S_F\n",
    "    Nmx = S_F\n",
    "        \n",
    "    zeta = eta / (1 - eta)\n",
    "    return Q0, Nmx, zeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute optimization input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the loaded daily price data to compute the corresponding yearly mean return and covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of factors\n",
    "fnum = len(list_factors)\n",
    "\n",
    "# Number of securities (We subtract fnum to account for factors at the end of the price data)\n",
    "N = df_prices.shape[1] - fnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the same using the factor model. First we compute logarithmic return statistics and use them to compute the factor exposures and covariances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_log, S_log = compute_inputs(df_prices, return_log=True)\n",
    "R, F = scenarios(m_log, S_log, fnum)\n",
    "\n",
    "# Center factors, so we have the same model as in the article (Goldfarb--Iyengar 2003). \n",
    "F -= F.mean(axis=0)\n",
    "\n",
    "# Compute factor model\n",
    "mu, B, S_F, diag_S_theta, X = factor_model(R, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the parameters of the uncertainty sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty set parameters\n",
    "omega = 0.95\n",
    "percent = 0.2\n",
    "mu0, gamma = unc_mu(mu, diag_S_theta, X, omega)\n",
    "beta0, Gmx, rho = unc_beta(B, diag_S_theta, X, omega)\n",
    "diag_S_theta_upper = unc_d(diag_S_theta, percent)\n",
    "Q0, Nmx, zeta = unc_q(S_F, X, omega)\n",
    "\n",
    "# To get back the non_robust case, we have to zero the bounds\n",
    "gamma_z = np.zeros(N)\n",
    "rho_z = np.zeros(N)\n",
    "zeta_z = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the optimizer function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the optimization for a range of risk aversion parameter values: $\\delta = 10^{-1},\\dots,10^{2}$. We compute the efficient frontier this way both with and without using factor model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute efficient frontier with and without factor model\n",
    "deltas = np.logspace(start=-1, stop=2, num=20)[::-1] / 2\n",
    "df_result_orig = EfficientFrontier(N, mu0, gamma_z, beta0, Gmx, rho_z, diag_S_theta_upper, Q0, Nmx, zeta_z, deltas)\n",
    "df_result_robust = EfficientFrontier(N, mu0, gamma, beta0, Gmx, rho, diag_S_theta_upper, Q0, Nmx, zeta, deltas)\n",
    "df_result_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set small negatives to zero to make plotting work\n",
    "mask = df_result_orig < 0\n",
    "mask.iloc[:, :-8] = False\n",
    "df_result_orig[mask] = 0\n",
    "\n",
    "# Set small negatives to zero to make plotting work\n",
    "mask = df_result_robust < 0\n",
    "mask.iloc[:, :-8] = False\n",
    "df_result_robust[mask] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the efficient frontier for both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = df_result_robust.plot(x=\"risk\", y=\"return\", style=\"-o\", xlabel=\"portfolio risk (std. dev.)\", ylabel=\"portfolio return\", grid=True)\n",
    "df_result_orig.plot(ax=ax, x=\"risk\", y=\"return\", style=\"-o\", xlabel=\"portfolio risk (std. dev.)\", ylabel=\"portfolio return\", grid=True)   \n",
    "ax.legend([\"robust return\", \"return\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the portfolio composition for both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot portfolio composition\n",
    "my_cmap = LinearSegmentedColormap.from_list(\"non-extreme gray\", [\"#111111\", \"#eeeeee\"], N=256, gamma=1.0)\n",
    "ax1 = df_result_robust.set_index('risk').iloc[:, 4:].plot.area(colormap=my_cmap, xlabel='portfolio risk (std. dev.)', ylabel=\"x\")\n",
    "ax1.grid(which='both', axis='x', linestyle=':', color='k', linewidth=1)\n",
    "ax2 = df_result_orig.set_index('risk').iloc[:, 4:].plot.area(colormap=my_cmap, xlabel='portfolio risk (std. dev.)', ylabel=\"x\") \n",
    "ax2.grid(which='both', axis='x', linestyle=':', color='k', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
